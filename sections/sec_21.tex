\setcounter{subsection}{21-1}
\subsection{The Metric Topology (continued)}

\exercise{1}{
  Let $A \ss X$.
  If $d$ is a metric for the topology of $X$, show that $d \rest A \times A$ is a metric for the subspace topology on $A$.
}
\sol{
  \qproof{
    Let us denote the restricted function $d \rest A \times A$ by $d'$.
    Clearly $d'$ is a metric on $A$, since for $x,y \in A$ we have $d'(x,y) = d(x,y)$ and $d$ has all the properties of a metric.
    We show that the metric topology induced by $d'$ is the same as the subspace topology using Lemma~13.3 in both directions.

    First we show that $B_{d'}(x,\e) = A \cap B_d(x,\e)$ for any $x \in A$ and $\e > 0$.
    For any $y \in B_{d'}(x,\e)$ we have that clearly $y \in A$ since the metric $d'(y,x)$ must be defined, and $d(y,x) = d'(y,x) <\e$ so that also $y \in B_d(x,\e)$.
    Thus $y \in A \cap B_d(x,\e)$, and hence $B_{d'}(x,\e) \ss A \cap B_d(x,\e)$.
    For the other direction suppose that $y \in A \cap B_d(x,\e)$ so that $y \in A$ and $y \in B_d(x,\e)$.
    Thus $y$ and $x$ are in $A$ so that $d'(y,x)$ is defined and $d'(y,x) = d(y,x) < \e$, and hence $y \in B_{d'}(x,\e)$.
    This shows that $B_{d'}(x,\e) \sps A \cap B_d(x,\e)$, which in turn shows that the two sets are the same.    
    
    Now, clearly each basis element of the metric topology $B_{d'}(x,\e) = A \cap B_d(x,\e)$ is also a basis element of the subspace topology by Lemma~16.1.
    Hence for any $x \in A$ we have that $B_m = B_{d'}(x,\e)$ is a basis element of the metric topology and $B_s = A \cap B_d(x,\e)$ is a basis element of the subspace topology.
    But $B_m = B_s$ so that $x \in B_s \ss B_m$ and $x \in B_m \ss B_s$ so that each topology is finer than the other by Lemma~13.3.
    Thus they are the same topologies.
  }
}

\def\ivfp{\inv{f'}}
\exercise{2}{
  Let $X$ and $Y$ be metric spaces with metrics $d_X$ and $d_Y$, respectively.
  Let $f: X \to Y$ have the property that for every pair of points $x_1, x_2$ of $X$,
  \gath{
    d_Y(f(x_1), f(x_2)) = d_X(x_1, x_2) \,.
  }
  Show that $f$ is an imbedding.
  It is called an \boldit{isometric imbedding} of $X$ in $Y$.
}
\sol{
  First, let $Z = f(X)$ and let $f'$ denote the function $f$ with the range restricted to $Z$ so that clearly $f'$ is surjective.
  First we must show that $f$ and therefore also $f'$ is injective, from which it clearly follows that $f'$ is a bijection.
  So suppose that $x_1,x_2 \in X$ where $f(x_1) = f(x_2)$.
  Then we have that
  \gath{
    d_X(x_1, x_2) = d_Y(f(x_1), f(x_2)) = d_Y(f(x_1), f(x_1)) = 0
  }
  by property (1) of the metric $d_Y$, so that it must be that $x_1 = x_2$ since $d_X$ is a metric and $d_X(x_1, x_2) = 0$.
  This of course means that $f$ and $f'$ are injective and hence $f'$ is bijective.

  We show that $f'$ and $\ivfp$ are both continuous using Theorem~21.1 since $X$ and $Z$ are both metric spaces, noting that $Z \ss Y$ is a metric space with metric $d_Z = d_Y \rest Z \times Z$ by the previous exercise.
  So consider any $x \in X$ and any $\e > 0$, and let $\d = \e$.
  Then for any $x_1,x_2 \in X$ where $d_X(x_1,x_2) < \d$ we have
  \gath{
    d_Z(f'(x_1), f'(x_2)) = d_Y(f(x_1), f(x_2)) = d_X(x_1,x_2) < \d = \e \,,
  }
  which suffices to show that $f'$ is continuous.
  A similar argument shows that $\ivfp: Z \to X$ is continuous.
  For $y_1,y_2 \in Z$ and $\e > 0$, again let $\d = \e$ and suppose that $d_Z(y_1,y_2) <\d$.
  Let $x_1 = \ivfp(y_1)$ and $x_2 = \ivfp(y_2)$.
  Then we have
  \ali{
    d_X(\ivfp(y_1), \ivfp(y_2)) &= d_X(x_1, x_2) = d_Y(f(x_1),  f(x_2)) = d_Y(f'(x_1), f'(x_2)) \\
    &= d_Y(f'(\ivfp(y_1)), f'(\ivfp(y_2))) = d_Y(y_1, y_2) \\
    &= d_Z(y_1, y_2) < \d = \e \,,
  }
  which of course shows that $\ivfp$ is also continuous.
  This shows that $f'$ is a homeomorphism so that $f$ is an imbedding as desired.
}

\def\bdi{\bar{d_i}}
\exercise{3}{
  Let $X_n$ be a metric space with metric $d_n$, for $n \in \pints$.
  \eparts{
  \item Show that
    \gath{
      \r(x,y) = \max\braces{d_1(x_1,y_1), \ldots, d_n(x_n, y_n)}
    }
    is a metric for the product space $\cpfin{X}{n}$.
  \item Let $\bdi = \min\braces{d_i, 1}$.
    Show that
    \gath{
      D(x,y) = \sup\braces{\bdi(x_i,y_i)/i}
    }
    is a metric for the product space $\prod X_i$.
  }
}
\sol{
  \begin{lem} \label{lem:metricc:sup}
    Suppose that $(x_\a)_{\a \in J}$ and $(y_\a)_{\a \in J}$ are sequences of real numbers indexed by $J$ and that $\braces{x_\a}$ and $\braces{y_\a}$ are bounded above so that $\sup\braces{x_\a}$ and $\sup\braces{y_\a}$ exist.
    We assert the following facts:
    \lparts{
    \item If $x_\a \leq y_\a$ for each $\a \in J$, then $\sup\braces{x_\a} \leq \sup\braces{y_\a}$.
    \item $\sup\braces{x_\a + y_\a}$ exists and $\sup\braces{x_\a + y_\a} \leq \sup\braces{x_\a} + \sup\braces{y_\a}$.
    }
  \end{lem}
  \qproof{
    The proofs of both parts are quite simple.
    Regarding part (1) we have that $x_\b \leq y_\b \leq \sup\braces{y_\a}$ for any $\b \in J$ so that clearly $\sup\braces{y_\a}$ is an upper bound of the set $\braces{x_\a}$.
    It then follows by the definition of the supremum as the least upper bound that $\sup\braces{x_\a} \leq \sup\braces{y_\a}$ as desired.

    For part (2) consider any $\b \in J$.
    Clearly $x_\b \leq \sup\braces{x_\a}$ and $y_\b \leq \sup\braces{y_\a}$ so that
    \gath{
      x_\b + y_\b \leq \sup\braces{x_\a} + \sup\braces{y_\a} \,.
    }
    Since $\b$ was arbitrary, this shows that $\sup\braces{x_\a} + \sup\braces{y_\a}$ is an upper bound for the set $\braces{x_\a + y_\a}$.
    Therefore $\sup\braces{x_\a + y_\a} \leq \sup\braces{x_\a} + \sup\braces{y_\a}$ as desired by the definition of the supremum as the least upper bound.
  }

  \mainprob
  
  (a)
  \qproof{
    First we must show that $\r$ is a metric at all.
    In what follows suppose that $x,y,z \in \cpfin{X}{n}$ and that $k$ and $m$ are elements of $\intsfin{n}$ such that
    \gath{
      \r(x,y) = \max\braces{d_1(x_1,y_1), \ldots, d_n(x_n, y_n)} = d_k(x_k, y_k)
    }
    and
    \gath{
      \r(x,z) = \max\braces{d_1(x_1,z_1), \ldots, d_n(x_n, z_n)} = d_m(x_m, z_m) \,.
    }
    First, we have $\r(x,y) = d_k(x_k, y_k) \geq 0$ since $d_k$ is a metric.
    If $x = y$ then of course $x_k = y_k$ so that $\r(x,y) = d_k(x_k, y_k) = 0$.
    Now suppose that $\r(x,y) = 0$ and consider any $l \in \intsfin{n}$.
    Then we have that $d_l(x_l, y_l) \geq 0$ and that $d_l(x_l, y_l) \leq \r(x,y) = 0$, and hence it must be that $d_l(x_l, y_l) = 0$ so that $x_l = y_l$ since $d_l$ is a metric.
    Since $l$ was arbitrary, this shows that $x = y$, which shows that $\r$ satisfies part (1) of the definition of a metric.

    As usual, part (2) of the definition is the easiest to show since
    \ali{
      \r(x,y) &= \max\braces{d_1(x_1,y_1), \ldots, d_n(x_n, y_n)} = \\
      &= \max\braces{d_1(y_1,x_1), \ldots, d_n(y_n, x_n)} = \\
      &= \r(y,x) \,,
    }
    as we have that each $d_l(x_l, y_l) = d_l(y_l, x_l)$ since $d_l$ is a metric.
    Lastly, for part (3) we have
    \gath{
      \r(x,z) = d_m(x_m, z_m) \leq d_m(x_m, y_m) + d_m(y_m, z_m) \leq \r(x,y) + \r(y,z)
    }
    since of course $d_m$ is a metric.
    This completes the proof that $\r$ is a proper metric.

    Now we show that both topologies are the same using Lemma~13.3.
    So suppose that $x \in \cpfin{X}{n}$ and $B_\r(x,\e)$ is any basis element of the metric topology and let $B = \prod_{i=1}^n B_{d_i}(x_i, \e)$, which is clearly a basis element of the product topology that contains $x$ since each $B_{d_i}(x_i, \e)$  is open in the metric space $X_i$.
    Now suppose that $y \in B$ so that each $y_i \in B_{d_i}(x_i, \e)$.
    So, for every $i \in \intsfin{n}$, we have $d_i(y_i, x_i) < \e$ so that clearly
    \gath{
      \r(y,x) = \max\braces{d_1(y_1,x_1), \ldots, d_n(y_n, x_n)} < \e \,,
    }
    which shows that $y \in B_\r(x,\e)$.
    This shows that $x \in B \ss B_\r(x,\e)$ so that $B_\r(x,\e)$ the product topology is finer than the metric topology by Lemma~13.3.

    Now consider again any $x \in \cpfin{X}{n}$ and any basis element $B = \prod_{i=1}^n U_i$ of the product topology.
    Then of course each $U_i$ is open in $X_i$ and $x_i \in U_i$ so that there is a ball $B_{d_i}(x_i, \e_i)$ such that $B_{d_i}(x_i, \e_i) \ss U_i$ by Lemma~\ref{lem:metric:ball}.
    Let $\e = \min\braces{\e_1, \ldots, \e_n}$ and consider the basis element $B_\r(x,\e)$ in the metric space induced by $\r$.
    Clearly $x \in B_\r(x,\e)$ so consider any $y \in B_\r(x,\e)$ so that
    \gath{
      \r(y,x) = \max\braces{d_1(y_1,x_1), \ldots, d_n(y_n, x_n)} < \e \,.
    }
    Then, for any $i \in \intsfin{n}$, we have
    \gath{
      d_i(y_i,x_i) \leq \r(x,\e) < \e \leq \e_i
    }
    so that $y_i \in B_{d_i}(x_i,\e_i) \ss U_i$.
    Since this is true of any $i \in \intsfin{n}$, it follows that $y \in \prod_{i=1}^n U_i = B$.
    We can then conclude that $x \in B_\r(x,\e) \ss B$ since $y$ was arbitrary.
    This shows that the $\r$-metric topology is finer than the product topology, again by Lemma~13.3.
    Hence the two topologies are the same as desired.
  }

  (b)
  \qproof{
    First we show that the metric $D$ is well-defined and is in fact a metric.
    In what follows suppose that $x,y,z \in \prod X_i$.
    For any $j \in \pints$ we have that $0 < 1 \leq j$ so that $1/j \leq 1$.
    We also have that $\bd_j(x_j,y_j) = \min\braces{d_j(x_j,y_j), 1} \leq 1$ so that $\bd_j(x_j,y_j) / j \leq 1/j \leq 1$.
    Hence $1$ is an upper bound for the set $\braces{\bd_i(x_i,y_i)/i}$ since $j$ was arbitrary, so that
    \gath{
      D(x,y) = \sup\braces{\bd_i(x_i,y_i)/i}
    }
    exists and hence $D$ is well defined.

    To show part (1) of the definition of a metric, pick any $j \in \pints$ so that clearly $\bd_j(x_j,y_j) \geq 0$ and hence $\bd_j(x_j,y_j)/j \geq 0$ also since $j \geq 1 > 0$.
    Thus we have
    \gath{
      D(x,y) = \sup\braces{\bd_i(x_i,y_i)/i} \geq \bd_j(x_j,y_j)/j \geq 0 \,.
    }
    If $x = y$ then we have that $x_j = y_j$ for any $j \in \pints$.
    Thus $\bd_j(x_j,y_j) = 0$ since $\bd_j$ is a standard bounded metric, and therefore
    \gath{
      \frac{\bd_j(x_j,y_j)}{j} = \frac{0}{j} = 0 \,.
    }
    Since $j$ was arbitrary, this shows that
    \gath{
      D(x,y) = \sup\braces{\frac{\bd_i(x_i,y_i)}{j}} = \sup\braces{0} = 0 \,.
    }
    On the other hand, if $D(x,y) = 0$ then, for any $j \in \pints$, we have
    \gath{
      0 \leq \frac{\bd_j(x_j,y_j)}{j} \leq \sup\braces{\frac{\bd_i(x_i,y_i)}{i}} = D(x,y) = 0 \,.
    }
    This shows that $\bd_j(x_j,y_j)/j = 0$ so that clearly $\bd_j(x_j,y_j) = 0$ as well, from which it follows that $x_j = y_j$ since $\bd_j$ is a standard bounded metric.
    Since $j$ was arbitrary, this shows that $x = y$, which completes the proof of part (1).

    Showing part (2) is quite easy:
    \gath{
      D(x,y) = \sup\braces{\frac{\bd_i(x_i,y_i)}{i}} = \sup\braces{\frac{\bd_i(y_i,x_i)}{i}} = D(x,y)
    }
    since $\bd_i$ is a standard bounded metric for every $i \in \pints$.

    For part (3) consider any $j \in \pints$.
    Then
    \gath{
      \bd_j(x_j,z_j) \leq \bd_j(x_j,y_j) + \bd_j(y_j,z_j)
    }
    since $\bd_j$ is a standard bounded metric.
    Then of course
    \gath{
      \frac{\bd_j(x_j,z_j)}{j} \leq \frac{\bd_j(x_j,y_j) + \bd_j(y_j,z_j)}{j} = \frac{\bd_j(x_j,y_j)}{j} + \frac{\bd_j(y_j,z_j)}{j}
    }
    since $j \geq 1 > 0$.
    Then, since $j$ was arbitrary this shows that
    \ali{
      D(x,z) &= \sup\braces{\frac{\bd_i(x_i,z_i)}{i}} \leq \sup\braces{\frac{\bd_i(x_i,y_i)}{i} + \frac{\bd_i(y_i,z_i)}{i}} \\
      &\leq \sup\braces{\frac{\bd_i(x_i,y_i)}{i}} + \sup\braces{\frac{\bd_i(y_i,z_i)}{i}} \\
      &= D(x,y) + D(y,z)
    }
    by both parts of Lemma~\ref{lem:metricc:sup}.
    This of course completes the proof that $D$ is a well defined metric.

    Now we show that the metric topology induced by $D$ is the same as the product topology on $\prod X_i$, which we do using Lemma~13.3.
    So consider any $x \in \prod X_i$ and any basis element of the metric topology $B_D(x,\e)$ centered at $x$.
    Clearly there is a positive integer $N$ large enough such that $N > 2/\e$, and so $1/N < \e/2$.
    Now define the sets
    \gath{
      U_i = \begin{cases}
        B_{d_i}(x_i,\e/2) & i < N \\
        \reals & i \geq N
      \end{cases}
    }
    for $i \in \pints$, and the set $B = \prod U_i$.
    Clearly $B$ is a basis element of the product topology since each $U_i$ is open in $X_i$ and $U_i \neq \reals$ for only finitely many $i$, namely when $i < N$.
    Clearly also $x \in B$ since each $x_i \in U_i$.
    Now suppose that $y \in B$ and consider any $j \in \pints$.
    If $j < N$ then we of course have that $y_j \in U_j = B_{d_j}(x_j, \e/2)$ so that
    \gath{
      \frac{\bd_j(y_j,x_j)}{j} \leq \bd_j(y_j,x_j) \leq d_j(y_j,x_j) < \e/2
    }
    since $j \geq 1$.
    If $j \geq N$ then we have $1/j \leq 1/N$ so that
    \gath{
      \frac{\bd_j(y_i,x_i)}{j} \leq \frac{1}{j} \leq \frac{1}{N} < \frac{\e}{2}
    }
    since $\bd_j(y_j,x_j) \leq 1$.
    Since $j$ was arbitrary, this shows that
    \gath{
      D(y,x) = \sup\braces{\frac{\bd_i(y_i,x_i)}{i}} \leq \frac{\e}{2} < \e
    }
    so that $y \in B_D(x,\e)$.
    Therefore $x \in B \ss B_D(x,\e)$ since $y$ was arbitrary.
    Hence the product topology is finer than the metric topology by Lemma~13.3.

    Now again consider any $x \in \prod X_i$ and any basis element $B = \prod U_i$ of the product topology where $x \in B$.
    Then of course each $U_i$ is open in $X_i$ and there is a finite subset $J \ss \pints$ where $U_i = \reals$ for every $i \notin J$.
    Of course also $x \in U_i$ for each $i \in \pints$.
    For any $j \in J$ we have that $x \in U_j$ and $U_j$ is open in $X_i$ so that there is a basis element $B_{d_j}(x_j, \e_j)$ such that $B_{d_j}(x_j, \e_j) \ss U_j$.
    So let $\e = \min(\braces{\e_j \where j \in J} \cup \braces{1})$ and $k = \max\braces{j \where j \in J}$, which both exists since $J$ is finite, and also clearly $\e > 0$.

    Now consider the set $B_D(x,\e/k)$, which is a basis element of the metric topology that clearly contains $x$.
    Suppose that $y \in B_D(x,\e/k)$ so that $D(y,x) < \e/k$.
    Then, for any $j \in \pints$, clearly $y_i \in \reals = U_i$ if $j \neq J$.
    On the other hand, if $j \in J$ then we have that $k \geq j$ so that $1/k \leq 1/j$.
    We also have
    \gath{
      \frac{\bd(y_j,x_j)}{j} \leq \sup\braces{\frac{\bd_i(y_i,x_i)}{i}} = D(y,x) < \frac{\e}{k} \leq \frac{\e}{j} \leq \frac{1}{j}
    }
    since $1/k \leq 1/j$ and $\e \leq 1$.
    Therefore $\bd_j(y_j,x_j) < 1$ so that it must be that $\bd_j(y_j,x_j) = d_j(y_j,x_j)$.
    Hence we have $d_j(y_j,x_j) = \bd_j(y_j,x_j) < \e \leq \e_j$ so that $y_j \in B_{d_j}(x_j,\e_j) \ss U_j$.
    Therefore $y_i \in U_i$ for all $i \in \pints$ so that $y \in \prod U_i = B$.
    Since $y$ was arbitrary, this shows that $x \in B_D(x,\e) \ss B$, which in turn proves that the metric topology is also finer than the product topology by Lemma~13.3.
    Thus the two topologies must be the same.
  }
}

\def\vc{\vect{c}}
\def\vd{\vect{d}}
\def\vone{\vect{1}}
\exercise{4}{
  Show that $\realsl$ and the ordered square satisfy the first countability axiom.
  (This result does not, of course, imply that they are metrizable.)
}
\sol{
  \qproof{
    Suppose that $x$ is any element of $\realsl$.
    Define the sets $U_n = \clop{x,x+1/n}$ for $n \in \pints$.
    Clearly this is a countable collection of neighborhoods of $x$ since each $U_n$ is a basis element of $\realsl$ and $x \in U_n$.
    Now consider any other neighborhood $U$ of $x$ so that there is a basis element $B = \clop{a,b}$ that contains $x$ and $B \ss U$.
    Thus of course $a \leq x < b$.
    There is clearly a positive integer $N$ large enough that $N > 1/(b-x)$, noting that $b-x > 0$ since $x < b$.
    Now consider any $y \in U_N = \clop{x,x+1/N}$ so that $x \leq y < x+1/N$.
    Then we have
    \ali{
      \frac{1}{b-x} &< N \\
      \frac{1}{N} &< b - x & \text{(since both $N \geq 1 > 0$ and $b-x>0$)}\\
      x + \frac{1}{N} &< b
    }
    so that $y \leq x + 1/N < b$.
    As we also clearly have $a \leq x \leq y$ it follows that $y \in \clop{a,b} = B \ss U$.
    Thus $U_N \ss U$ since $y$ was arbitrary.
    This shows that $\realsl$ satisfies the first countability axiom since $U$ and $x$ were arbitrary.

    Now recall that the ordered square is the set $I \times I$ where $I = [0,1]$ with the dictionary order topology.
    In what follows let $\prec$ denote the dictionary order on $I \times I$.
    So suppose that $\vx = x_1 \times x_2 \in I \times I$ so that of course $0 \leq x_1 \leq 1$ and $0 \leq x_2 \leq 1$.
    Now define the following
    \ali{
      a_{n,1} &= \begin{cases}
        \max\braces{x_1-1/n, 0} & x_2 = 0 \\
        x_1 & x_2 > 0
      \end{cases} &
      b_{n,1} &= \begin{cases}
        \min\braces{x_1+1/n, 1} & x_2 = 1 \\
        x_1 & x_2 < 1
      \end{cases} \\
      a_{n,2} &= \max\braces{x_2-1/n,0} &
      b_{n,2} &= \min\braces{x_2+1/n,1}
    }
    for $n \in \pints$, which are all well defined since it is never the case that $x_2 < 0$ or $x_2 > 1$.
    Also define $\va_n = a_{n,1} \times a_{n,2}$ and $\vb_n = b_{n,1} \times b_{n,2}$ for $n \in \pints$.
    Lastly, define the sets
    \gath{
      U_n = \begin{cases}
        \clop{\va_n, \vb_n} & x_1 = x_2 = 0 \\
        \opcl{\va_n, \vb_n} & x_1 = x_2 = 1 \\
        (\va_n, \vb_n) & \text{otherwise}
      \end{cases}
    }
    for $n \in \pints$, noting that the intervals are in the dictionary order so that these are basis elements of the dictionary order topology and so are open.

    As it is not obvious with all the different cases going on, we now show that $\vx \in U_n$ for every $n \in \pints$.
    So consider any $n \in \pints$.

    Case: $x_2 = 0$.
    Then we have $b_{n,1} = x_1$ and $x_2 < \min\braces{x_2+1/n,1} = b_{n,2}$ since $x_2 = 0 < 1$ and clearly $x_2 < x_2+1/n$.
    This shows that $\vx \prec \vb_n$.
    \begin{indpar}
      Case: $x_1 = 0$.
      Then we clearly have that $x_1-1/n < x_1 = 0$, and hence $a_{n,1} = \max\braces{x_1-1/n,0} = 0 = x_1$.
      Also clearly $a_{n,1} = 0 = x_2$ since $x_2 = 0$.
      Hence $\va_n = 0 \times 0 = \vx$ so that $\va_n \prece \vx$ is true.
      This shows that $\vx \in \clop{\va_n,\vb_n} = U_n$.

      Case: $x_1 > 0$.
      Then we have $x_1-1/n < x_1$ and $0 < x_1$ so that $a_{n,1} = \max\braces{x_1-1/n,0} < x_1$.
      Therefore $\va_n \prec \vx$ so that $\vx \in (\va_n, \vb_n) = U_n$.
    \end{indpar}

    Case: $x_2 = 1$.
    Then we have $a_{n,1} = x_1$ and $a_{n,2} = \max\braces{x_2-1/n,0} < x_2$ since $x_2 = 1 > 0$ and clearly $x_2 > x_2-1/n$.
    This shows that $\va_n \prec \vx$.
    \begin{indpar}
      Case: $x_1 = 1$.
      Then $x_1+1/n > x_1 = 1$ so that $b_{n,1} = \min\braces{x_1+1/n,1} = 1 = x_1$.
      Likewise we have that $x_2+1/n > x_2 = 1$ so that $b_{n,2} = \min\braces{x_2+1/n, 1} = 1$.
      Thus $\vb_n = 1 \times 1 = \vx$ and hence $\vx \prece \vb_n$ is true.
      Therefore $\vx \in \opcl{\va_n, \vb_n} = U_n$.

      Case: $x_1 < 1$.
      Then we have $x_1+1/n > x_1$ and $1 > x_1$ so that $b_{n,1} = \min\braces{x_1+1/n,1} > x_1$.
      Therefore $\vx \prec \vb_n$ so that $\vx \in (\va_n, \vb_n) = U_n$.
    \end{indpar}

    Case: $0 < x_2 < 1$.
    Then $a_{n,1} = x_1$, and $x_2-1/n < x_2$ and $0 < x_2$ so that $a_{n,2} = \max\braces{x_2-1/n,0} < x_2$.
    This shows that $\va_n \prec \vx$.
    Similarly $b_{n,1} = x_1$, and $x_2+1/n > x_2$ and $1 > x_2$ so that $b_{n,2} = \min\braces{x_2+1/n,1} > x_2$.
    This shows that $\vx \prec \vb_n$.
    Therefore we have $\vx \in (\va_n,\vb_n) = U_n$.
    
    Hence $\vx \in U_n$ in all of the exhaustive cases so that $\braces{U_n}_{n \in \pints}$ is a countable collection of neighborhoods of $\vx$.

    Lastly consider any other neighborhood of $U$ of $\vx$ in the dictionary order topology.
    Then there is a basis element $B$ of the dictionary order topology such that $\vx \in B \ss U$.
    Then we have that either $B = \clop{\vc, \vd}$ where $\vc = \vze$, $B = (\vc, \vd)$, or $B = \opcl{\vc, \vd}$ where $\vd = \vone$ (where we denote $\vone = 1 \times 1$).
    Now we set $N_a,N_b \in \pints$ based on the different cases we might have.
    First, we know that no matter what we have $\vc \prece \vx$ since $\vx\in B$.
    We therefore have:

    Case: $c_1 < x_1$.
    If $x_2 > 0$ then set $N_a = 1$, and otherwise $x_2 = 0$ and there is an $N_a$ large enough such that $N_a > 1/(x_1-c_1)$, noting that this is defined since $x_1-c_1>0$.

    Case: $c_1 = x_1$.
    Then it has to be that $c_2 \leq x_2$ since $\vc \prece \vx$.
    If $c_2 = x_2$ then it must be that $B = \clop{\vc, \vd}$ and $\vc = \vx = \vze$, so just set $N_a = 1$.
    On the other hand, if $c_2 < x_2$, then there must be an $N_a$ large enough such that $N_a > 1/(x_2-c_2)$, noting that $x_2 - c_2 > 0$.

    Now we set $N_b$ in an analogous way, noting that we have $\vx \prece \vd$ no matter what since $\vx \in B$:

    Case: $x_1 < d_1$.
    If $x_2 < 1$ then simply set $N_b = 1$, and otherwise $x_2 = 1$ and there is an $N_b$ large enough such that $N_b > 1/(d_1-x_1)$, noting that $d_1-x_1 > 0$.

    Case: $x_1 = d_1$.
    Then it must be that $x_2 \leq d_2$ since $\vx \prece \vd$.
    If $x_2 = d_2$ then it has to be that $B = \opcl{\vc, \vd}$ and $\vx = \vd = \vone$, so just set $N_b = 1$.
    On the other hand, if $x_2 < d_2$, then there is an $N_b$ large enough such that $N_b > 1/(d_2-x_2)$, noting that $d_2-x_2 > 0$.

    Now let $N = \max\braces{N_a, N_b}$, and we claim that $U_N \ss B$ in every case.
    We have again know that $\vc \prece \vx$ so that we have:

    Case: $c_1 < x_1$.
    If $x_2 > 0$ then $c_1 < x_1 = a_{N,1}$.
    If $x_2 = 0$ then we have $N \geq N_a > 1/(x_1-c_1)$, from which it readily follows that $c_1 < x_1 - 1/n \leq a_{N,1}$.
    Thus either way we have $c_1 < a_{N,1}$ so that $\vc \prec \va_N$.

    Case: $c_1 = x_1$.
    If also $c_2 = x_2$ then again it has to be that $B = \clop{\vc, \vd}$ and $\vc = \vx = \vze$.
    In this case it was established above that $U_N = \clop{\va_N, \vb_N}$ and $\va_N = \vze$.
    So we have here that $\vc = \vze \prece \vze = \va_N$.
    On the other hand if $c_2 < x_2$ then $N \geq N_a > 1/(x_2-c_2)$, from which it follows that $c_2 < x_2 - 1/n \leq a_{N,2}$.
    Also $c_1 = x_1 = a_{N,1}$ so that $\vc \prec \va_N$ since $0 \leq c_2 < x_2$.

    We also of course again have that $\vx \prece \vd$ so that

    Case: $x_1 < d_1$.
    If $x_2 < 1$ then $b_{N,1} = x_1 < d_1$.
    If $x_2 = 1$ then we have $N \geq N_b > 1/(d_1-x_1)$, from which it follows that $b_{N,1} \leq x_1 + 1/N < d_1$.
    Hence either was $b_{N,1} < d_1$ so that $\vb_N \prec \vd$.

    Case: $x_1 = d_1$.
    If also $x_2 = d_2$ then again it has to be that $B = \opcl{\vc, \vd}$ and $\vd = \vx = \vone$.
    In this case it was established above that $U_N = \opcl{\va_N, \vb_N}$ and $\vb_N = \vone$.
    So we have here that $\vb_N = \vone \prece \vone = \vd$.
    On the other hand if $x_2 < d_2$ then we have $N \geq N_b > 1/(d_2-x_2)$, from which it readily follows that $b_{N,2} \leq x_2+1/N < d_2$.
    We also have $b_{N,1} = x_1 = d_1$ so that $\vb_N \prec \vd$ since $x_2 < d_2 \leq 1$.

    Therefore in every case we have that $\vc \prec \va_N$ except when $\vc = \vx = \va_N = \vze$ so that $U_N = \clop{\vze, \vb_N}$ and $B = \clop{\vze, \vd}$.
    Similarly we always have $\vb_N \prec \vd$ except when $\vb_N = \vx = \vd = \vone$ so that $U_N = \opcl{\va_N, \vone}$ and $B = \opcl{\vc, \vone}$.
    When $\vc = \vx = \va_N = \vze$ we cannot have $\vx = \vone$, so that $\vb_N \prec \vd$.
    Analogously, when $\vb_N = \vx = \vd = \vone$ it cannot be that $\vx = \vze$, and hence $\vc \prec \va_N$.
    Otherwise we have $U_N = (\va_N, \vb_N)$, $\vc \prec \va_N$, and $\vb_N \prec \vd$ so that in every case $\vx \in U_N \ss B \ss U$.
    Since $U$ was an arbitrary neighborhood and $\vx$ was also arbitrary, this shows that $I \times I$ satisfies the first countability axiom as desired.
  }
}

\exercise{5}{
  \begin{thrm*}
    Let $x_n \to x$ and $y_n \to y$ in the space $\reals$.
    Then
    \ali{
      x_n + y_n &\to x + y \\
      x_n - y_n &\to x - y \\
      x_n y_n &\to x y \,,
    }
    and provided that each $y_n \neq 0$ and $y \neq 0$,
    \gath{
      x_n/y_n \to x/y \,.
    }
  \end{thrm*}
      [Hint: Apply Lemma~21.4; recall from the exercises of \S 19 that if $x_n \to x$ and $y_n \to y$, then $x_n \times y_n \to x \times y$.]
}
\sol{
  \qproof{
    First, we have that the sequence $x_n \times y_n$ converges to $x \times y$ in the product space $\reals \times \reals$ by Exercise~19.6 since both $x_n \to x$ and $y_n \to y$ in $\reals$.
    Now suppose that $f : \reals \times \reals \to \reals$ is continuous.
    Then we have that
    \gath{
      \lim_{n \to \infty} f(x_n \times y_n) = f\parens{\lim_{n \to \infty} x_n \times y_n} = f(x \times y)
    }
    by Theorem~21.3.
    Now, we have that addition, subtraction, and multiplication are all continuous functions from $\reals \times \reals$ to $\reals$ by Lemma~21.4.
    It then follows that for the continuous function $+: \reals \times \reals \to \reals$ we have
    \gath{
      \lim_{n \to \infty} (x_n + y_n) = \lim_{n \to \infty} +(x_n \times y_n) = +(x \times y) = x + y \,.
    }
    It similarly follows that $x_n - y_n \to x - y$ and $x_n y_n \to x y$ as desired.

    Regarding the quotient, we note that $(y_n)$ is a sequence in the subspace topology $\reals - \braces{0}$ since each $y_n \neq 0$.
    We also note that $y \neq 0$ and hence also $y \in \reals - \braces{0}$ so that the sequence $(y_n)$ converges to a point still within the space $\reals - \braces{0}$.
    It then again follows that $x_n \times y_n \to x \times y$ in the product space $\reals \times (\reals - \braces{0})$ by Exercise~19.6.
    Since the quotient function is continuous from $\reals \times (\reals - \braces{0})$ to $\reals$ by Lemma~21.4, it then follows as before that $x_n/y_n \to x/y$ by Theorem~21.3 just as we would like.
  }
}

\exercise{6}{
  Define $f_n : [0,1] \to \reals$ by the equation $f_n(x) = x^n$.
  Show that the sequence $(f_n(x))$ converges for each $x \in [0,1]$, but that the sequence $(f_n)$ does not converge uniformly.
}
\sol{
  First we build up a little more theory
  \begin{defin} \label{def:metricc:pointwise}
    Let $f_n: X \to Y$ be a sequence of functions from a set $X$ to topological space $Y$.
    We say that the sequence of functions converges \emph{pointwise} to a function $f: X \to Y$ if the sequence $(f_n(x))$ converges to $f(x)$ for every $x \in X$.
  \end{defin}

  \begin{lem} \label{lem:metricc:pwunique}
    Let $f_n : X \to Y$ be a sequence of functions from a set $X$ to topological space $Y$.
    If $Y$ is a Hausdorff space and $(f_n)$ converges pointwise to $f$, then $f$ is unique.
  \end{lem}
  \qproof{
    Suppose that $(f_n)$ converges pointwise to two distinct functions $f$ and $g$.
    Since they are distinct, there is an $x_0 \in X$ where $f(x_0) \neq g(x_0)$.
    But then the sequence $(f_n(x_0))$ converges to both of the distinct points $f(x_0)$ and $g(x_0)$ since $(f_n)$ converges pointwise to both $f$ and $g$.
    As $Y$ is Hausdorff, this violates Theorem~17.10 so that $(f_n)$ can only converge pointwise to a unique function.
  }
  
  \begin{lem} \label{lem:metricc:unifpw}
    Let $f_n : X \to Y$ be a sequence of functions from a set $X$ to metric space $Y$ with metric $d$.
    If $(f_n)$ converges uniformly to a function $f$, then it also converges pointwise to $f$.
  \end{lem}
  \qproof{
    Suppose that $(f_n)$ converges uniformly to $f$ and consider any $x_0 \in X$ and $\e > 0$.
    Then there is an $N \in \pints$ where $d(f_n(x), f(x)) < \e$ for all $n > N$ and $x \in X$.
    Then, since $x_0 \in X$, we have $d(f_n(x_0), f(x_0)) < \e$ for all $n \geq N+1$ since then $n > N$.
    This shows that the sequence $(f_n(x_0))$ converges to $f(x_0)$ since $\e$ was arbitrary.
    Since $x_0$ was arbitrary, this shows that $(f_n)$ converges pointwise to $f$ as desired.
  }

  \mainprob
  
  \qproof{
    First we show that the sequence $(f_n)$ converges pointwise to the function $g: [0,1] \to \reals$ defined by
    \gath{
      g(x) = \begin{cases}
        0 & x < 1 \\
        1 & x = 1
      \end{cases}
    }
    for $x \in [0,1]$.
    This of course shows that $(f_n(x))$ converges for each $x \in [0,1]$ by Definition~\ref{def:metricc:pointwise}.
    
    So consider any such $x \in [0,1]$ so that we have the following exhaustive cases:

    Case: $x = 0$.
    Then $f_n(x) = x^n = 0^n = 0$ for any $n \in \pints$.
    Thus clearly the sequence $(f_n(x)) = (0,0,\ldots)$ converges to $0$.

    Case: $x = 1$.
    Somewhat similarly we have $f_n(x) = x^n = 1^n = 1$ for every $n \in \pints$ so that clearly the sequence $(f_n(x)) = (1,1,\ldots)$ converges to $1$.

    Case: $0 < x < 1$.
    Here we show that, for any $x \in (0,1)$, that the sequence $(f_n(x))$ is strictly decreasing and that it is bounded below by $0$.
    We prove this using induction on $n$.
    So first for $n = 1$ we have
    \ali{
      0 < x &< 1 \\
      0 < x^2 &< x & \text{(since $x > 0$)} \\
      0 < f_2(x) &< f_1(x) \\
      0 < f_{n+1}(x) &< f_n(x) \,.
    }
    For the inductive step suppose that $f_n(x) > 0$ and $f_{n+1}(x) < f_n(x)$.
    Then we of course have $0 < f_n(x) = x^n$ so that clearly $0 = x \cdot 0 < x \cdot x^n = x^{n+1} = f_{n+1}(x)$ as well since $x > 0$.
    We also clearly have
    \ali{
      f_{n+1} &< f_n(x) \\
      x^{n+1} &< x^n \\
      x \cdot x^{n+1} &< x \cdot x^n & \text{(since $x > 0$)} \\
      x^{n+2} &< x^{n+1} \\
      f_{n+2}(x) &< f_{n+1}(x) \,,
    }
    which completes the inductive step.
    
    Hence the sequence is strictly decreasing (and therefore of course non-increasing) and bounded below by zero, from which it follows that it converges by a theorem analogous in an obvious way to that shown in Exercise~21.11 part (a).
    So suppose that the sequence converges to the value $a$.
    Then of course also the sequence $(f_{n+1}(x))$ must also converge to $a$.
    Thus we have
    \gath{
      a = \lim_{n \to \infty} f_{n+1}(x) = \lim_{n \to \infty} x^{n+1} = \lim_{n \to \infty} x \cdot x^n = \lim_{n \to \infty} x f_n(x) = x \lim_{n \to \infty} f_n(x) = xa \,,
    }
    where we note that clearly the function $h(y) = xy$ for $y \in \reals$ is clearly continuous so that
    \gath{
      \lim_{n \to \infty} x f_n(x) = \lim_{n \to \infty} h(f_n(x)) = h\parens{\lim_{n \to \infty} f_n(x)} = x \lim_{n \to \infty} f_n(x)
    }
    by Theorem~21.3.
    Therefore we have $a = xa$ so that it would be that $1 = x$ if $a$ were any nonzero value.
    However, we know that $x < 1$ so it must be that $a = 0$.
    This completes the proof that $(f_n)$ converges pointwise to $g$.

    It then becomes fairly easy to show that $(f_n(x))$ does not converge uniformly.
    Consider any function $f: [0,1] \to \reals$.
    If $f \neq g$ then $(f_n)$ cannot converge pointwise to $f$ since it was shown to converge pointwise to $g$ above and $g$ is unique by Lemma~\ref{lem:metricc:pwunique} since $\reals$ is Hausdorff.
    Hence $(f_n)$ cannot converge uniformly to $f$ by the converse of Lemma~\ref{lem:metricc:unifpw} since it does even not converge pointwise.
    On the other hand if $f = g$ then clearly $f = g$ has a discontinuity at $1$ so that it is not continuous.
    However each $f_n(x) = x^n$ is continuous on $[0,1]$ by elementary calculus.
    This shows that $(f_n)$ cannot converge uniformly to $f=g$ since this would violate Theorem~21.6.
    Therefore $(f_n)$ does converge uniformly to any function since $f$ was arbitrary.
  }
}

\exercise{7}{
  Let $X$ be a set, and let $f_n: X \to \reals$ be a sequence of functions.
  Let $\br$ be the uniform metric on the space $\reals^X$.
  Show that the sequence $(f_n)$ converges uniformly to the function $f: X \to \reals$ if any only if the sequence converges to $f$ as elements of the metric space $(\reals^X, \br)$.
}
\sol{
  \qproof{
    $(\imp)$ First suppose that $(f_n)$ converges uniformly to $f$ in the functional sense.
    Consider any $\e > 0$.
    Then, by the definition of uniform convergence there is an $N \in \pints$ where
    \gath{
      d(f_n(x), f(x)) < \e/2
    }
    for all $n > N$ and $x \in X$, noting that $d$ of course denotes the usual metric on $\reals$.
    Now consider any $x_0 \in X$ and an $n \geq N+1$ so that $n > N$.
    Then of course we have
    \gath{
      \bd(f_n(x_0),f(x_0)) = \min\braces{d(f_n(x_0),f(x_0)), 1} \leq d(f_n(x_0),f(x_0)) < \e/2\,,
    }
    from which it follows that
    \gath{
      \br(f_n, f) = \sup\braces{\bd(f_n(x),f(x)) \where x \in X} \leq \e/2 < \e
    }
    since $x_0$ was arbitrary.
    This shows that $f_n \in B_{\br}(f, \e)$.
    Since $n \geq N+1$ and $\e > 0$ were both arbitrary, this shows that the sequence $(f_n)$ converges to $f$ as elements of the metric space $\reals^X$.

    $(\pmi)$ Now suppose that $(f_n)$ converges to $f$ in the uniform metric space $\reals^X$.
    Consider any $\e > 0$ and let $\d = \min\braces{\e,1}$.
    Then, since $B_{\br}(f,\d)$ is a neighborhood of $f$ in the uniform metric space, there is an $N \in \pints$ where $f_n \in B_{\br}(f,\d)$ for all $n \geq N$.
    So consider any $n > N$ and $x_0 \in X$.
    Then clearly $f_n \in B_{\br}(f,\d)$ so that $\br(f_n,f) < \d$.
    Hence
    \gath{
      \bd(f_n(x_0),f(x_0)) \leq \sup\braces{\bd(f_n(x),f(x)) \where x \in X} = \br(f_n,f)  < \d \leq 1 
    }
    so it has to be that $d(f_n(x_0),f(x_0)) = \bd(f_n(x_0),f(x_0))$ since
    \gath{
      \bd(f_n(x_0),f(x_0)) = \min\braces{d(f_n(x_0),f(x_0)), 1} < 1 \,.
    }
    Therefore we have
    \gath{
      d(f_n(x_0),f(x_0)) = \bd(f_n(x_0),f(x_0)) \leq \br(f_n,f) < \d \leq \e \,.
    }
    Since $n > N$, $x_0 \in X$, and $\e > 0$ were arbitrary, this shows that $(f_n)$ converges to $f$ uniformly in the functional sense.
  }
}

\exercise{8}{
  Let $X$ be a topological space and let $Y$ be a metric space.
  Let $f_n: X \to Y$ be a sequence of continuous functions.
  Let $x_n$ be a sequence of points of $X$ converging to $x$.
  Show that if the sequence $(f_n)$ converges uniformly to $f$, then $(f_n(x_n))$ converges to $f(x)$.
}
\sol{
  \qproof{
    Suppose that $(f_n)$ converges to $f$ uniformly and let $d$ denote the metric for $Y$.
    Consider any $\e > 0$.
    Since $(f_n)$ converges to $f$ uniformly there is an $N_1 \in \pints$ where $d(f_n(x'),f(x')) < \e/2$ for any $n > N_1$ and $x' \in X$.
    We also know from the uniform limit theorem (Theorem~21.6) that $f$ is continuous since each $f_n$ is continuous.
    It then follows from Theorem~21.3 that the sequence $(f(x_n))$ converges to $f(x)$ since $x_n \to x$.
    Hence there is an $N_2 \in \pints$ such that $d(f(x_n),f(x)) < \e/2$ for all $n \geq N_2$.

    So set $N = \max\braces{N_1+1, N_2}$ and consider any $n \geq N$.
    Then of course $n \geq N \geq N_1+1 > N_1$ and $x_n \in X$ so that
    \gath{
      d(f_n(x_n), f(x_n)) < \e/2 \,.
    }
    We also have that $n \geq N \geq N_2$ so that
    \gath{
      d(f(x_n),f(x)) < \e/2 \,.
    }
    We then have
    \gath{
      d(f_n(x_n),f(x)) \leq d(f_n(x_n), f(x_n)) + d(f(x_n), f(x)) < \frac{\e}{2} + \frac{\e}{2} = \e
    }
    since $d$ is a metric, and so $f_n(x_n) \in B_d(f(x),\e)$.
    Since $n \geq N$ and $\e > 0$ were arbitrary, we have shown that the sequence $(f_n(x_n))$ converges to $f(x)$ in the metric space $Y$ by definition.
  }
}

\exercise{9}{
  Let $f_n: \reals \to \reals$ be the function
  \gath{
    f_n(x) = \frac{1}{n^3 [x-(1/n)]^2 + 1} \,.
  }
  See Figure~21.1.
  Let $f: \reals \to \reals$ be the zero function.
  \eparts{
  \item Show that $f_n(x) \to f(x)$ for each $x \in \reals$.
  \item Show that $f_n$ does not converge uniformly to $f$.
    (This shows that the converse of Theorem~21.6 does not hold; the limit function $f$ may be continuous even though the convergence is not uniform.)
  }
}
\sol{
  (a)
  \qproof{
    This is easy to show by evaluating the limit using techniques from elementary calculus.
    Fix $x \in \reals$ and first suppose that $x \neq 0$.
    Clearly $1/n \to 0$ as $n \to \infty$ so that $[x-(1/n)]^2 \to x^2$.
    Since $x^2 > 0$ it follows that $n^3 [x - (1/n)]^2 \to n^3 x^2 \to \infty$ as $n \to \infty$.
    Hence the overall function
    \gath{
      f_n(x) = \frac{1}{n^3 [x-(1/n)]^2 + 1} \to \frac{1}{\infty + 1} \to 0 = f(x)
    }
    as $n \to \infty$.
    Of course this is a little informal, but it can be justified rigorously using nothing more than Exercise~21.5.
    If $x = 0$ then we clearly have
    \gath{
      f_n(x) = f_n(0) = \frac{1}{n^3 [-(1/n)]^2 + 1} = \frac{1}{n^3/n^2 + 1} = \frac{1}{n+1} \to 0 = f(x)
    }
    as $n \to \infty$.
  }

  (b)
  \qproof{
    Let $\e = 1/2$ and consider any $N \in \pints$ and let $n = N+1$ so of course $n > N$.
    Also set $x = 1/n$.
    Then we have
    \gath{
      f_n(x) = \frac{1}{n^3 [x-(1/n)]^2 + 1} = \frac{1}{n^3 [(1/n)-(1/n)]^2 + 1} = \frac{1}{n^3 \cdot 0 + 1} = \frac{1}{1} = 1
    }
    whereas of course $f(x) = 0$.
    We therefore have
    \gath{
      d(f_n(x), f(x)) = d(1,0) = \abs{1-0} = 1 \geq 1/2 = \e \,.
    }
    This shows the negation of the definition of uniform convergence so that $(f_n)$ does not converge uniformly to $f$ as desired.
    }
  Note that this also shows that $(f_n)$ does not uniformly converge to any function at all since, if it did, it can only converge uniformly to $f$ since this is the only function to which it converges pointwise.
  This follows from Lemmas~\ref{lem:metricc:pwunique} and \ref{lem:metricc:unifpw} as in Exercise~21.6.
}

\exercise{10}{
  Using the closed set formulation of continuity (Theorem~18.1), show that the following are closed subsets of $\reals^2$:
  \ali{
    A &= \braces{x \times y \where xy = 1} \,, \\
    S^1 &= \braces{x \times y \where x^2 + y^2 = 1} \,, \\
    B^2 &= \braces{x \times y \where x^2 + y^2 \leq 1} \,.
  }
  The set $B^2$ is called the (closed) \boldit{unit ball} in $\reals^2$.
}
\sol{
  \qproof{
    Regarding the set $A$, the function $f: \reals \times \reals \to \reals$ defined by $f(x \times y) = xy$ is simply the multiplication function, which is continuous by Lemma~21.4.
    Clearly the set $A = \inv{f}(\braces{1})$ by definition.
    We also have that $\braces{1}$ is closed in $\reals$ by Theorem~17.8 since $\reals$ is Hausdorff.
    Thus $A = \inv{f}(\braces{1})$ is closed in $\reals \times \reals = \reals^2$ by Theorem~18.1 since $f$ is continuous.

    For $S^1$, let $d$ denote the usual euclidean metric on $\reals \times \reals$, which we know induces the same topology as the product topology.
    We also know from Exercise~20.3 that $d: \reals \times \reals \to \reals$ is continuous.
    The function $f: \reals \times \reals \to \reals$ by
    \gath{
      f(x \times y) = d(x,y) \cdot d(x,y) = [d(x,y)]^2 = \squares{\sqrt{x^2 + y^2}}^2 = x^2 + y^2 \,.
    }
    is also then continuous by Theorem~21.5 being the product of two continuous functions.
    As previously mentioned, the finite set $\braces{1}$ is closed in $\reals$.
    We also have that $S^1 = \inv{f}(\braces{1})$ by definition, which then also must be closed in $\reals \times \reals = \reals^2$ again by Theorem~18.1 since $f$ continuous.

    Regarding the closed unit ball $B^2$, define $f = d \cdot d$ as above for $S^1$, which is of course still continuous.
    Define the subset $C = \braces{x \in \reals \where 0 \leq x \leq 1}$ of $\reals$.
    We claim that $B^2 = \inv{f}(C)$.
    This is pretty obvious since clearly $0 \leq f(x \times y) = x^2 + y^2 \leq 1$ for any $x \times y \in B^2$ by definition so that $f(x \times y) \in C$ and hence $x \times y \in \inv{f}(C)$.
    Conversely, for any $x \times y \in \inv{f}(C)$, we have that $f(x \times y) \in C$ so that $0 \leq f(x \times y) = x^2 + y^2 \leq 1$ so that $x \times y \in B^2$ by definition.
    This shows the desired equality of $B^2$ and $\inv{f}(C)$.
    As it is trivial to show that $C$ is closed in $\reals$, and $f$ is continuous, it follows that $B^2 = \inv{f}(C)$ is also closed in $\reals \times \reals = \reals^2$, again by Theorem~18.1.
  }
}

\exercise{11}{
  Prove the following standard facts about infinite series:
  \eparts{
  \item Show that if $(s_n)$ is a bounded sequence of real numbers and $s_n \leq s_{n+1}$ for each $n$, then $(s_n)$ converges.
  \item Let $(a_n)$ be a sequence of real numbers; define
    \gath{
      s_n = \sum_{i=1}^n a_i \,.
    }
    If $s_n \to s$, we say that the \boldit{infinite series}
    \gath{
      \sum_{i=1}^\infty a_i
    }
    converges to $s$ also.
    Show that if $\sum a_i$ converges to $s$ and $\sum b_i$ converges to $t$, then $\sum (ca_i + b_i)$ converges to $cs+t$.
  \item Prove the \boldit{comparison test} for infinite series: If $\abs{a_i} \leq b_i$ for each $i$, and if the series $\sum b_i$ converges, then the series $\sum a_i$ converges.
    [Hint: Show that the series $\sum \abs{a_i}$ and $\sum c_i$ converge, where $c_i = \abs{a_i} + a_i$.]
  \item Given a sequence of functions $f_n: X \to \reals$, let
    \gath{
      s_n(x) = \sum_{i=1}^n f_i(x) \,.
    }
    Prove the \boldit{Weierstrass M-test} for uniform convergence: If $\abs{f_i(x)} \leq M_i$ for all $x \in X$ and all $i$, and if the series $\sum M_i$ converges, then the sequence $(s_n)$ converges uniformly to a function $s$.
    [Hint: Let $r_n = \sum_{i=n+1}^\infty M_i$.
    Show that if $k > n$, then $\abs{s_k(x) - s_n(x)} \leq r_n$; conclude that $\abs{s(x) - s_n(x)} \leq r_n$.]
  }
}
\sol{
  (a)
  \qproof{
    Clearly image of the sequence $S = \braces{s_n \where n \in \pints}$ is a set of real numbers that is bounded above since the sequence is bounded above.
    Therefore $s = \sup S$ exists, noting that of course $s_n \leq s$ for any $n \in \pints$ since $s_n \in S$.
    We claim that $s_n \to s$.
    So consider any $\e > 0$ so that clearly $s-\e < s$, and hence $s-\e$ cannot be an upper bound of $S$ (since $s$ is the least upper bound).
    Thus there is an $N \in \pints$ where $s - \e < s_N$.
    Then, for any $n \geq N$ we have that $s-\e < S_N \leq s_n \leq s$ since the sequence is non-decreasing.
    Thus we have
    \gath{
      s - \e < s_n \\
      s - s_n < \e \\
      \abs{s - s_n} < \e \\
      d(s_n, s) < \e
    }
    since $s \geq s_n$, where $d$ denotes the usual metric on $\reals$.
    Hence $s_n \in B_d(s, \e)$, which shows that the sequence converges to $s$ since $n \geq N$ and $\e$ were arbitrary.
  }

  (b)
  \qproof{
    Define the partials sums
    \ali{
      s_n &= \sum_{i=1}^n a_i &
      t_n &= \sum_{i=1}^n b_i
    }
    of $\sum a_i$ and $\sum b_i$ so that $s_n \to s$ and $t_n \to t$ by the definition of infinite series.
    Also define the constant sequence $c_n = c$ for real $c$, so that of course $c_n \to c$.
    For any $n \in \pints$, we of course have
    \gath{
      c_n s_n + t_n = c \sum_{i=1}^n a_i + \sum_{i=1}^n b_i = \sum_{i=1}^n c a_i + \sum_{i=1}^n b_i = \sum_{i=1}^n (c a_i + b_i)
    }
    since these are just finite sums.
    It then follows from what was shown in Exercise~21.5 that
    \gath{
      \sum_{i=1}^\infty (c a_i + b_i) = \lim_{n \to \infty} \sum_{i=1}^n (c a_i + b_i) = \lim_{n \to \infty} (c_n s_n + t_n) = cs + t
    }
    as desired.
  }

  (c)
  \qproof{
    Denote the partial sums
    \ali{
      s_n &= \sum_{i=1}^n \abs{a_i} &
      t_n &= \sum_{i=1}^n b_i \,.
    }
    We know that $(t_n)$ converges by the definition of an infinite series, since $\sum b_i$ converges.
    So suppose that $t_n \to t$.
    We also clearly have that $0 \leq \abs{a_i} \leq b_i$ for all $i \in \pints$, so that each term in both sums is always non-negative.
    It then follows that the sequence of partial sums $(s_n)$ and $(t_n)$ are non-decreasing, and moreover that $t_n \leq t$ for all $n \in \pints$.
    Lastly, since each $\abs{a_i} \leq b_i$, it follows from a simple inductive argument that each $s_n \leq t_n \leq t$.
    Hence $(s_n)$ is a non-decreasing sequence that is also bounded (by $t$), and so it converges by part (a).
    Therefore the infinite series $\sum \abs{a_i}$ converges by definition.
    Denote its convergence value by $u$.

    Now, we also have that clearly
    \gath{
      -\abs{a_i} \leq a_i \leq \abs{a_i} \\
      0 \leq \abs{a_i} + a_i \leq 2 \abs{a_i}
    }
    for every $i \in \pints$, and that $\sum 2\abs{a_i}$ converges to $2u$ by what was shown in part (b).
    Therefore, by the same argument as above, the sequence of partial sums of $\sum (\abs{a_i} + a_i)$ is non-decreasing and bounded by $2u$ so that the series converges, say the the value $v$.
    Then, again by part (b), we have that the series
    \gath{
      \sum_{i=1}^\infty a_i = \sum_{i=1}^\infty (\abs{a_i} + a_i - \abs{a_i}) = \sum_{i=1}^\infty \squares{(\abs{a_i} + a_i) + (-1)\abs{a_i}}
    }
    converges to $v - u$ since both $v = \sum (\abs{a_i} + a_i)$ and $u = \sum \abs{a_i}$ have been shown to converge.
    This shows the desired result.
  }

  (d)
  \qproof{
    First, since $\abs{f_i(x)} \leq M_i$ for all $x \in X$ and $\sum M_i$ converges, it follows from part (c) that the series $\sum f_i(x)$ converges (as does the sequence $(s_n(x))$) for each $x \in X$.
    So set the function $s : X \to \reals$ to $s(x) = \lim_{n \to \infty} s_n(x)$ for each $x \in X$.
    Thus $(s_n)$ converges pointwise to $s$ by Definition~\ref{def:metricc:pointwise}, and $s$ can be thought of as the (pointwise) infinite sum of the functions $f_i$.

    To show that $s_n \to s$ uniformly, first define
    \gath{
      r_n = \sum_{i=n+1}^\infty M_i
    }
    for $n \in \pints$ as the partial series of $\sum M_i$ as in Definition~\ref{def:metric:pseries}.
    Now consider any $x \in X$, any $n \in \pints$, and any $k > n$.
    Then we have that
    \gath{
      \abs{s_k(x) - s_n(x)} = \abs{\sum_{i=1}^k f_i(x) - \sum_{i=1}^n f_i(x)} = \abs{\sum_{i=n+1}^k f_i(x)} \leq \sum_{i=n+1}^k \abs{f_i(x)} \leq \sum_{i=n+1}^k M_i \leq \sum_{i=n+1}^\infty M_i = r_n \,,
    }
    where we note that $\sum_{i=n+1}^k M_i \leq \sum_{i=n+1}^\infty M_i$ since each $M_i$ is non-negative.
    Since the absolute value function is continuous on $\reals$, it follows from Theorem~21.3 and Exercise~21.5 that the sequence $\abs{s_k(x) - s_n(x)}$ converges as $k \to \infty$, and moreover converges to $\abs{s(x) - s_n(x)}$ since $s_k(x) \to s(x)$ as $k \to \infty$ as shown above.
    Then, since the above inequality holds for any $k > n$, it follows from Lemma~\ref{lem:metric:seqleq} that
    \gath{
      \abs{s(x) - s_n(x)} = \lim_{k \to \infty} \abs{s_k(x) - s_n(x)} \leq \lim_{k \to \infty} r_n = r_n \,.
    }

    Now consider any $\e > 0$.
    We know from Lemma~\ref{lem:metric:pseries} that the sequence of partial series $(r_n)$ converges to zero since each $M_i$ is non-negative.
    Hence there is an $N \in \pints$ where $\abs{r_n - 0} < \e$ for all $n \geq N$.
    Moreover, Lemma~\ref{lem:metric:pseries} asserts that each $r_n \geq 0$ so that $\abs{r_n - 0} = \abs{r_n} = r_n < \e$ for all $n \geq N$.
    Thus, for any $n > N$ and any $x \in X$, we have
    \gath{
      \abs{s(x) - s_n(x)} \leq r_n < \e \,.
    }
    This suffices to show that $(s_n)$ uniformly converges to $s$ since $\e$ was arbitrary.
  }
}

\exercise{12}{
  Prove continuity of the algebraic operations on $\reals$, as follows: Use the metric $d(a,b) = \abs{a-b}$ on $\reals$ and the metric on $\reals^2$ given by the equation
  \gath{
    \r((x,y),(x_0,y_0)) = \max\braces{\abs{x-x_0},\abs{y-y_0}} \,.
  }
  \eparts{
  \item Show that addition is continuous.
    [Hint: Given $\e$, let $\d=\e/2$ and note that
      \gath{
        d(x+y, x_0+y_0) \leq \abs{x-x_0} + \abs{y-y_0} \,.]
    }
  \item Show that multiplication is continuous.
    [Hint: Given $(x_0,y_0)$ and $0 < \e < 1$, let
      \gath{
        3\d = \e/(\abs{x_0} + \abs{y_0} + 1)
      }
      and note that
      \gath{
        d(xy, x_0 y_0) \leq \abs{x_0}\abs{y-y_0} + \abs{y_0}\abs{x-x_0} + \abs{x-x_0}\abs{y-y_0} \,.]
    }
  \item Show that the operation of taking reciprocals is a continuous map from $\reals-\braces{0}$ to $\reals$.
    [Hint: Show the inverse image of the interval $(a,b)$ is open.
      Consider five cases, according as $a$ and $b$ are positive, negative, or zero.]
  \item Show that the subtraction and quotient operations are continuous.
  }
}
\sol{
  First we note that this exercise proves Lemma~21.4 in the text.
  We also note that the square metric $\r$ as defined above induces the usual product topology on $\reals^2$, which was shown in Theorem~20.3.

  (a)
  \qproof{
    We show the continuity of $+: \reals^2 \to \reals$ using Theorem~21.1.
    So consider any $x_0 \times y_0 \in \reals^2$ and any $\e>0$.
    Following the hint, let $\d=\e/2$ and consider any $x \times y \in \reals^2$ where $\r(x \times y,x_0 \times y_0) < \d$.
    Then we have that
    \gath{
      \r(x \times y,x_0 \times y_0) = \max\braces{\abs{x-x_0},\abs{y-y_0}} < \d = \e/2 \,,
    }
    from which it clearly follows that both $\abs{x-x_0} < \e/2$ and $\abs{y-y_0} < \e/2$.
    Then we have
    \ali{
      d(+(x \times y), +(x_0 \times y_0)) &= d(x+y,x_0+y_0) = \abs{x+y - (x_0+y_0)} \\
      &= \abs{(x-x_0) + (y-y_0)} \leq \abs{x-x_0} + \abs{y-y_0} \\
      &< \frac{\e}{2} + \frac{\e}{2} = \e \,.
    }
    This suffices to show that $+$ is continuous by Theorem~21.1 since $\e$ was arbitrary.
  }

  (b)
  \qproof{
    We again use Theorem~21.1 so show that the multiplication function $\times : \reals^2 \to \reals$ is continuous.
    So consider any $x \times y \in \reals^2$ and any $\e > 0$.
    Let
    \gath{
      \d = \min\braces{\frac{\e}{\abs{x_0} + \abs{y_0} + 1}, 1}
    }
    so that of course $\d > 0$.
    Now consider any $x \times y \in \reals^2$ where $\r(x \times y,x_0 \times y_0) < \d$.
    Then of course
    \gath{
      \r(x \times y,x_0 \times y_0) = \max\braces{\abs{x-x_0},\abs{y-y_0}} < \d
    }
    so that both $\abs{x-x_0} < \d$ and $\abs{y-y_0} < \d$.
    We then have
    \ali{
      d(\times(x \times y),\times(x_0 \times y_0)) &= d(xy, x_0 y_0) = \abs{xy - x_0 y_0} \\
      &= \abs{xy - x_0 y_0 + (x_0 y - x_0 y) + (x y_0 - x y_0) + (x_0 y_0 - x_0 y_0)} \\
      &= \abs{(x_0 y - x_0 y_0) + (x y_0 - x_0 y_0) + (xy - x y_0 - x_0 y + x_0 y_0)} \\
      &= \abs{x_0(y-y_0) + y_0(x-x_0) + (x-x_0)(y-y_0)} \\
      &\leq \abs{x_0(y-y_0)} + \abs{y_0(x-x_0)} + \abs{(x-x_0)(y-y_0)} \\
      &= \abs{x_0}\abs{y-y_0} + \abs{y_0}\abs{x-x_0} + \abs{x-x_0}\abs{y-y_0} \\
      &< \abs{x_0} \d + \abs{y_0} \d + \d^2 \\
      &\leq \abs{x_0} \d + \abs{y_0} \d + \d \\
      &= \d (\abs{x_0} + \abs{y_0} + 1) \\
      &\leq \frac{\e}{\abs{x_0} + \abs{y_0} + 1} (\abs{x_0} + \abs{y_0} + 1) \\
      &= \e \,,
    }
    where we have used the fact that $0 < \d \leq 1$, from which it follows that $\d^2 \leq d$.
  }
}
